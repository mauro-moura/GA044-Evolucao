{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def measure_execution_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time of {func.__name__}: {execution_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, hyperparameters):\n",
    "        self.hyperparameters = hyperparameters \n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Data from: https://www.kaggle.com/code/stefanbergstein/keras-deep-learning-on-titanic-data\n",
    "        \"\"\"\n",
    "        data = pd.read_csv('dataset/train.csv')\n",
    "        # Fill missing values\n",
    "        # Fill numerical columns with the median value\n",
    "        data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "        data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "        data['Sex'] = data['Sex'].fillna(data['Sex'].mode()[0])\n",
    "        data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "        \n",
    "        variables = ['Pclass','Sex', 'Age','Parch','SibSp','Embarked']\n",
    "        x = data[variables]\n",
    "        y = data[['Survived']]\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        x.loc[:, 'Sex'] = le.fit_transform(x['Sex'])\n",
    "        x.loc[:, 'Embarked'] = le.fit_transform(x['Embarked'])\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x = x.astype('float64')\n",
    "        x.loc[:, variables] = scaler.fit_transform(x[variables]).astype('float64')\n",
    "\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        return self.x_train, self.y_train\n",
    "    \n",
    "    def build_model(self):\n",
    "        input_layer = tf.keras.layers.Input(shape=(self.x_train.shape[1],))\n",
    "\n",
    "        dense = tf.keras.layers.Dense(self.hyperparameters['neurons_per_layer'], activation = 'relu', kernel_initializer = 'he_normal')(input_layer)\n",
    "        for _ in range(self.hyperparameters['num_layers'] - 1):\n",
    "            dense = tf.keras.layers.Dense(self.hyperparameters['neurons_per_layer'], activation = 'relu', kernel_initializer = 'he_normal')(dense)\n",
    "            if self.hyperparameters['dropout'] > 0:\n",
    "                dense = tf.keras.layers.Dropout(self.hyperparameters['dropout'])(dense)\n",
    "        \n",
    "        output_layer = tf.keras.layers.Dense(1,activation = 'sigmoid')(dense)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.hyperparameters['learning_rate'])\n",
    "        model.compile(loss='binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def train(self):\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5)]\n",
    "        self.score = self.model.fit(self.x_train, self.y_train, epochs=100, batch_size=self.hyperparameters['batch_size'],\n",
    "                               validation_data=(self.x_val, self.y_val), callbacks=callbacks)\n",
    "\n",
    "        return self.score\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate the model on the validation set.\"\"\"\n",
    "        return self.model.evaluate(self.x_val, self.y_val)[1]\n",
    "    \n",
    "    def run(self):\n",
    "        self.load_data()\n",
    "        self.build_model()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4149 - loss: 0.9356 - val_accuracy: 0.5307 - val_loss: 0.8154\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5247 - loss: 0.8498 - val_accuracy: 0.5475 - val_loss: 0.7655\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5213 - loss: 0.8014 - val_accuracy: 0.6369 - val_loss: 0.7213\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5421 - loss: 0.8124 - val_accuracy: 0.6425 - val_loss: 0.6835\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5977 - loss: 0.7644 - val_accuracy: 0.6425 - val_loss: 0.6510\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.7132 - val_accuracy: 0.6480 - val_loss: 0.6237\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6381 - loss: 0.6698 - val_accuracy: 0.6760 - val_loss: 0.6001\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.6263 - val_accuracy: 0.6927 - val_loss: 0.5803\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6606 - loss: 0.6630 - val_accuracy: 0.7263 - val_loss: 0.5631\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6537 - loss: 0.6556 - val_accuracy: 0.7821 - val_loss: 0.5473\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6539 - loss: 0.6254 - val_accuracy: 0.8045 - val_loss: 0.5340\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7006 - loss: 0.5798 - val_accuracy: 0.7989 - val_loss: 0.5224\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.5732 - val_accuracy: 0.8045 - val_loss: 0.5110\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.5389 - val_accuracy: 0.8045 - val_loss: 0.5007\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7620 - loss: 0.5230 - val_accuracy: 0.8101 - val_loss: 0.4927\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.5839 - val_accuracy: 0.8101 - val_loss: 0.4858\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.5285 - val_accuracy: 0.8101 - val_loss: 0.4798\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7423 - loss: 0.5330 - val_accuracy: 0.7933 - val_loss: 0.4742\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7709 - loss: 0.5018 - val_accuracy: 0.7933 - val_loss: 0.4677\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7796 - loss: 0.5006 - val_accuracy: 0.7933 - val_loss: 0.4635\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.5131 - val_accuracy: 0.7933 - val_loss: 0.4599\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.4678 - val_accuracy: 0.7933 - val_loss: 0.4555\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.5015 - val_accuracy: 0.7933 - val_loss: 0.4521\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.4984 - val_accuracy: 0.7933 - val_loss: 0.4487\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4560 - val_accuracy: 0.7989 - val_loss: 0.4454\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 0.5060 - val_accuracy: 0.8101 - val_loss: 0.4436\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.5075 - val_accuracy: 0.8101 - val_loss: 0.4418\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.4526 - val_accuracy: 0.8101 - val_loss: 0.4392\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4550 - val_accuracy: 0.8101 - val_loss: 0.4370\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7940 - loss: 0.4821 - val_accuracy: 0.8101 - val_loss: 0.4361\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.5076 - val_accuracy: 0.8101 - val_loss: 0.4348\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.4727 - val_accuracy: 0.8101 - val_loss: 0.4340\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.4672 - val_accuracy: 0.8045 - val_loss: 0.4317\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'learning_rate': 10**-4,\n",
    "    'num_layers': 2,\n",
    "    'neurons_per_layer': 64,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.3,\n",
    "}\n",
    "model = Model(hyperparameters)\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optmize\n",
    "\n",
    "- Learning rate: 1e-6 an 1e-1\n",
    "- Number of hidden Layers\n",
    "- Batch Size\n",
    "- Number of neurons\n",
    "- Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel():\n",
    "    def __init__(self):\n",
    "        self.y_true = np.empty([])\n",
    "        self.y_pred = np.empty([])\n",
    "    \n",
    "    def initialize_population(self, initial_phrase, population_size:int, phrase_length:int):\n",
    "        \"\"\"\n",
    "        Initializes the population with random values\n",
    "        \"\"\"\n",
    "\n",
    "        def model(size, alphabet):\n",
    "            # alphabet_size = len(alphabet)\n",
    "            # return ''.join([alphabet[random.randint(0, alphabet_size - 1)] for i in range(size)])\n",
    "            return ''.join(np.random.choice(alphabet, size))\n",
    "\n",
    "        self.y_true = initial_phrase\n",
    "        self.y_pred = np.array([model(phrase_length, alphabet) for _ in range(population_size)])\n",
    "    \n",
    "    def fitness_function(self, y_true:str, y_pred:str):\n",
    "        count = 0\n",
    "        for i, letter in enumerate(y_true):\n",
    "            if letter == y_pred[i]:\n",
    "                count += 1\n",
    "        \n",
    "        count = count / len(y_true)\n",
    "        return count\n",
    "\n",
    "    def evaluate_fitness(self):\n",
    "        \"\"\"\n",
    "        Returns the fitness for all values in the y_true and y_pred arrays\n",
    "        \"\"\"\n",
    "        return np.array([self.fitness_function(self.y_true, y_pred) for y_pred in self.y_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolution():\n",
    "    def __init__(self, population_size, generations, mutation_rate, crossover_rate):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.population = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize the population with random hyperparameter configurations.\"\"\"\n",
    "        for _ in range(self.population_size):\n",
    "            individual = {\n",
    "                'learning_rate': 10**random.uniform(-6, -1),\n",
    "                'num_layers': random.randint(1, 5),\n",
    "                'neurons_per_layer': random.choice([32, 64, 128, 256, 512]),\n",
    "                'batch_size': random.choice([16, 32, 64, 128]),\n",
    "                'dropout': random.uniform(0.1, 0.5),\n",
    "            }\n",
    "            self.population.append(individual)\n",
    "    \n",
    "    def evaluate_population(self, model_class: Model):\n",
    "        \"\"\"Evaluate the fitness of the population based on validation accuracy.\"\"\"\n",
    "        fitness_scores = []\n",
    "        for individual in self.population:\n",
    "            model = model_class(individual)\n",
    "            model.load_data()\n",
    "            model.build_model()\n",
    "            model.train()\n",
    "            score = model.evaluate()\n",
    "            fitness_scores.append(score)\n",
    "        return fitness_scores\n",
    "\n",
    "    def select_parents(self, fitness_scores): # Discordo\n",
    "        \"\"\"Select parents using tournament selection.\"\"\"\n",
    "        selected_parents = []\n",
    "        for _ in range(self.population_size):\n",
    "            min_candidates = min(5, len(fitness_scores))\n",
    "            candidates = random.sample(list(zip(self.population, fitness_scores)), min_candidates)\n",
    "            best_candidate = max(candidates, key=lambda x: x[1])\n",
    "            selected_parents.append(best_candidate[0])\n",
    "        return selected_parents\n",
    "    \n",
    "    def crossover(self, parent1:dict, parent2:dict):\n",
    "        \"\"\"Perform single-point crossover.\"\"\"\n",
    "        child1 = parent1.copy()\n",
    "        child2 = parent2.copy()\n",
    "        if random.random() < self.crossover_rate:\n",
    "            crossover_point = random.randint(1, len(parent1.keys())-1)\n",
    "            parent_keys = sorted(parent2.keys())\n",
    "            for key in parent_keys[crossover_point:]:\n",
    "                child1[key] = parent2[key]\n",
    "            for key in parent_keys[:crossover_point]:\n",
    "                child1[key] = parent2[key]\n",
    "        return child1, child2\n",
    "\n",
    "    def mutate(self, individual):\n",
    "        \"\"\"Perform mutation on the individual.\"\"\"\n",
    "        for mutation_point in list(individual.keys()):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mutation_value = self.get_mutation_value(mutation_point)\n",
    "                individual[mutation_point] = mutation_value\n",
    "        return individual\n",
    "    \n",
    "    def get_mutation_value(self, parameter):\n",
    "        \"\"\"Generate a new value for a mutated parameter.\"\"\"\n",
    "        if parameter == 'learning_rate':\n",
    "            return 10**random.uniform(-6, -1)\n",
    "        elif parameter == 'num_layers':\n",
    "            return random.randint(1, 5)\n",
    "        elif parameter == 'neurons_per_layer':\n",
    "            return random.choice([32, 64, 128, 256, 512])\n",
    "        elif parameter == 'batch_size':\n",
    "            return random.choice([16, 32, 64, 128])\n",
    "        elif parameter == 'dropout':\n",
    "            return random.uniform(0, 0.5)\n",
    "    \n",
    "    def genetic_drift(self):\n",
    "        \"\"\"Introduce genetic drift (randomly changing some individuals).\"\"\"\n",
    "        individual = random.choice(self.population)\n",
    "        self.mutate(individual)\n",
    "    \n",
    "    @measure_execution_time\n",
    "    def run(self, model_class):\n",
    "        best_global = []\n",
    "        self.initialize_population()\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            print(f\"Generation {generation + 1}/{self.generations}\")\n",
    "            fitness_scores = self.evaluate_population(model_class)\n",
    "            parents = self.select_parents(fitness_scores)\n",
    "            \n",
    "            # Crossover and mutation to create new population\n",
    "            new_population = []\n",
    "            for i in range(0, len(parents), 2):\n",
    "                parent1 = parents[i]\n",
    "                parent2 = parents[i + 1]\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                # new_population.append(self.mutate(child1))\n",
    "                # new_population.append(self.mutate(child2))\n",
    "                new_population.append(child1)\n",
    "                new_population.append(child2)\n",
    "            \n",
    "            self.population = new_population\n",
    "            # Perform genetic drift\n",
    "            self.genetic_drift()\n",
    "\n",
    "            # Perform mutation\n",
    "            for i in range(len(self.population)):\n",
    "                self.population[i] = self.mutate(self.population[i])\n",
    "            \n",
    "            print(self.population, fitness_scores)\n",
    "            best_individual = max(zip(self.population, fitness_scores), key=lambda x: x[1])\n",
    "            print(f\"Best fitness in generation {generation + 1}: {best_individual[1]}\")\n",
    "        \n",
    "        return best_individual  # Return the best individual after all generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/1\n",
      "Epoch 1/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7002 - loss: 1.4024 - val_accuracy: 0.7654 - val_loss: 0.4749\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.6011 - val_accuracy: 0.8045 - val_loss: 0.4921\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.5468 - val_accuracy: 0.7821 - val_loss: 0.4861\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7939 - loss: 0.5140 - val_accuracy: 0.8101 - val_loss: 0.4777\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.4882 - val_accuracy: 0.7765 - val_loss: 0.5313\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.5239 - val_accuracy: 0.8045 - val_loss: 0.5289\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.4817 - val_accuracy: 0.7933 - val_loss: 0.5368\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5662 - val_accuracy: 0.7989 - val_loss: 0.5284\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6133 - val_accuracy: 0.7598 - val_loss: 0.4895\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.4948 - val_accuracy: 0.8045 - val_loss: 0.5458\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.5138 \n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6909 - loss: 0.6264 - val_accuracy: 0.8212 - val_loss: 0.4851\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7928 - loss: 0.5138 - val_accuracy: 0.8212 - val_loss: 0.4847\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7860 - loss: 0.4881 - val_accuracy: 0.7821 - val_loss: 0.5009\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8187 - loss: 0.4049 - val_accuracy: 0.7765 - val_loss: 0.4996\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.4232 - val_accuracy: 0.8101 - val_loss: 0.4609\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8026 - loss: 0.4602 - val_accuracy: 0.8212 - val_loss: 0.4493\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.4375 - val_accuracy: 0.8324 - val_loss: 0.4272\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.4315 - val_accuracy: 0.7989 - val_loss: 0.4605\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.4052 - val_accuracy: 0.7989 - val_loss: 0.4878\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.4093 - val_accuracy: 0.8101 - val_loss: 0.4534\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.3815 - val_accuracy: 0.8156 - val_loss: 0.4564\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3910 - val_accuracy: 0.8156 - val_loss: 0.4347\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8367 - loss: 0.3987 - val_accuracy: 0.8324 - val_loss: 0.4419\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.3861 - val_accuracy: 0.8101 - val_loss: 0.4503\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.4002 - val_accuracy: 0.8101 - val_loss: 0.4529\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.3955 - val_accuracy: 0.8101 - val_loss: 0.4704\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.4698 - val_accuracy: 0.7709 - val_loss: 0.5494\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4490 - val_accuracy: 0.7765 - val_loss: 0.5252\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.4876 \n",
      "[{'learning_rate': 0.02199756988625431, 'num_layers': 3, 'neurons_per_layer': 128, 'batch_size': 16, 'dropout': 0.4893002214296916}, {'learning_rate': 0.02199756988625431, 'num_layers': 3, 'neurons_per_layer': 256, 'batch_size': 32, 'dropout': 0.4348292687182622}] [0.8044692873954773, 0.7765362858772278]\n",
      "Best fitness in generation 1: 0.8044692873954773\n",
      "Execution time of run: 5.8281 seconds\n",
      "Best hyperparameters found: {'learning_rate': 0.02199756988625431, 'num_layers': 3, 'neurons_per_layer': 128, 'batch_size': 16, 'dropout': 0.4893002214296916} Best fitness found: 0.8044692873954773\n"
     ]
    }
   ],
   "source": [
    "population_size = 10\n",
    "generations = 5\n",
    "mutation_rate = 0.25\n",
    "crossover_rate = 0.75\n",
    "\n",
    "evo_optimizer = Evolution(population_size, generations, mutation_rate, crossover_rate)\n",
    "best_hyperparameters, best_fitness = evo_optimizer.run(Model)\n",
    "print(\"Best hyperparameters found:\", best_hyperparameters, \"Best fitness found:\", best_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class GridSearchOptimizer:\n",
    "    def __init__(self, param_grid):\n",
    "        self.param_grid = param_grid\n",
    "        self.best_params = None\n",
    "        self.best_score = -np.inf  # Best score initialized to negative infinity\n",
    "    \n",
    "    def generate_grid(self):\n",
    "        \"\"\"Generate all combinations of hyperparameters from the grid.\"\"\"\n",
    "        return list(itertools.product(*self.param_grid.values()))\n",
    "    \n",
    "    def evaluate_combination(self, model_class, params):\n",
    "        \"\"\"Evaluate a single combination of hyperparameters.\"\"\"\n",
    "        model = model_class(params)\n",
    "        model.load_data()\n",
    "        model.build_model()\n",
    "        model.train()\n",
    "        score = model.evaluate()\n",
    "        return score\n",
    "    \n",
    "    @measure_execution_time\n",
    "    def run(self, model_class):\n",
    "        \"\"\"Run the grid search over the parameter grid.\"\"\"\n",
    "        param_combinations = self.generate_grid()\n",
    "        \n",
    "        for params in param_combinations:\n",
    "            params = {key: val for key, val in zip(self.param_grid.keys(), params)}\n",
    "            print(f\"Evaluating combination: {params}\")\n",
    "            score = self.evaluate_combination(model_class, params)\n",
    "            \n",
    "            # Track best score and parameters\n",
    "            if score > self.best_score:\n",
    "                self.best_score = score\n",
    "                self.best_params = params\n",
    "            print(f\"Score: {score} for parameters: {params}\")\n",
    "        \n",
    "        print(f\"Best params: {self.best_params} with score: {self.best_score}\")\n",
    "        return self.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating combination: {'learning_rate': 1e-05, 'num_layers': 1, 'neurons_per_layer': 32, 'batch_size': 16, 'dropout': 0.2}\n",
      "Epoch 1/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3693 - loss: 1.1431 - val_accuracy: 0.3743 - val_loss: 1.1325\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3382 - loss: 1.1823 - val_accuracy: 0.3743 - val_loss: 1.1286\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3646 - loss: 1.1477 - val_accuracy: 0.3799 - val_loss: 1.1247\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3776 - loss: 1.1519 - val_accuracy: 0.3799 - val_loss: 1.1209\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3976 - loss: 1.1039 - val_accuracy: 0.3799 - val_loss: 1.1170\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3456 - loss: 1.1686 - val_accuracy: 0.3855 - val_loss: 1.1131\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3641 - loss: 1.1554 - val_accuracy: 0.3911 - val_loss: 1.1093\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3401 - loss: 1.1693 - val_accuracy: 0.3911 - val_loss: 1.1055\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3631 - loss: 1.1350 - val_accuracy: 0.3911 - val_loss: 1.1017\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3946 - loss: 1.0813 - val_accuracy: 0.3911 - val_loss: 1.0979\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3380 - loss: 1.1490 - val_accuracy: 0.3911 - val_loss: 1.0941\n",
      "Epoch 12/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3735 - loss: 1.1449 - val_accuracy: 0.4134 - val_loss: 1.0903\n",
      "Epoch 13/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 1.1396 - val_accuracy: 0.4134 - val_loss: 1.0867\n",
      "Epoch 14/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3852 - loss: 1.0949 - val_accuracy: 0.4134 - val_loss: 1.0829\n",
      "Epoch 15/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3818 - loss: 1.1330 - val_accuracy: 0.4134 - val_loss: 1.0792\n",
      "Epoch 16/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3907 - loss: 1.1013 - val_accuracy: 0.4134 - val_loss: 1.0755\n",
      "Epoch 17/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4039 - loss: 1.0863 - val_accuracy: 0.4134 - val_loss: 1.0719\n",
      "Epoch 18/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3891 - loss: 1.0908 - val_accuracy: 0.4134 - val_loss: 1.0683\n",
      "Epoch 19/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4049 - loss: 1.0895 - val_accuracy: 0.4134 - val_loss: 1.0646\n",
      "Epoch 20/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3949 - loss: 1.0991 - val_accuracy: 0.4134 - val_loss: 1.0609\n",
      "Epoch 21/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3780 - loss: 1.1015 - val_accuracy: 0.4134 - val_loss: 1.0574\n",
      "Epoch 22/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4153 - loss: 1.0468 - val_accuracy: 0.4134 - val_loss: 1.0538\n",
      "Epoch 23/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4012 - loss: 1.0783 - val_accuracy: 0.4134 - val_loss: 1.0503\n",
      "Epoch 24/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3874 - loss: 1.0795 - val_accuracy: 0.4134 - val_loss: 1.0467\n",
      "Epoch 25/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4107 - loss: 1.0635 - val_accuracy: 0.4134 - val_loss: 1.0432\n",
      "Epoch 26/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3950 - loss: 1.0705 - val_accuracy: 0.4134 - val_loss: 1.0397\n",
      "Epoch 27/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3788 - loss: 1.0946 - val_accuracy: 0.4134 - val_loss: 1.0361\n",
      "Epoch 28/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3941 - loss: 1.0619 - val_accuracy: 0.4190 - val_loss: 1.0327\n",
      "Epoch 29/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4128 - loss: 1.0315 - val_accuracy: 0.4190 - val_loss: 1.0292\n",
      "Epoch 30/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4132 - loss: 1.0094 - val_accuracy: 0.4190 - val_loss: 1.0258\n",
      "Epoch 31/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4030 - loss: 1.0517 - val_accuracy: 0.4190 - val_loss: 1.0223\n",
      "Epoch 32/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4443 - loss: 0.9922 - val_accuracy: 0.4190 - val_loss: 1.0190\n",
      "Epoch 33/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3992 - loss: 1.0304 - val_accuracy: 0.4190 - val_loss: 1.0155\n",
      "Epoch 34/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4113 - loss: 1.0358 - val_accuracy: 0.4190 - val_loss: 1.0121\n",
      "Epoch 35/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4105 - loss: 1.0223 - val_accuracy: 0.4190 - val_loss: 1.0088\n",
      "Epoch 36/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3804 - loss: 1.0790 - val_accuracy: 0.4190 - val_loss: 1.0054\n",
      "Epoch 37/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3863 - loss: 1.0639 - val_accuracy: 0.4190 - val_loss: 1.0021\n",
      "Epoch 38/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4023 - loss: 1.0536 - val_accuracy: 0.4134 - val_loss: 0.9987\n",
      "Epoch 39/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4086 - loss: 1.0311 - val_accuracy: 0.4134 - val_loss: 0.9955\n",
      "Epoch 40/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4159 - loss: 0.9834 - val_accuracy: 0.4134 - val_loss: 0.9922\n",
      "Epoch 41/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4098 - loss: 1.0032 - val_accuracy: 0.4134 - val_loss: 0.9889\n",
      "Epoch 42/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3978 - loss: 1.0143 - val_accuracy: 0.4134 - val_loss: 0.9856\n",
      "Epoch 43/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4421 - loss: 0.9532 - val_accuracy: 0.4134 - val_loss: 0.9826\n",
      "Epoch 44/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4094 - loss: 0.9877 - val_accuracy: 0.4134 - val_loss: 0.9792\n",
      "Epoch 45/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3625 - loss: 1.0207 - val_accuracy: 0.4134 - val_loss: 0.9760\n",
      "Epoch 46/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3931 - loss: 0.9950 - val_accuracy: 0.4134 - val_loss: 0.9728\n",
      "Epoch 47/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3980 - loss: 0.9667 - val_accuracy: 0.4134 - val_loss: 0.9697\n",
      "Epoch 48/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4306 - loss: 0.9633 - val_accuracy: 0.4134 - val_loss: 0.9665\n",
      "Epoch 49/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4180 - loss: 0.9487 - val_accuracy: 0.4134 - val_loss: 0.9633\n",
      "Epoch 50/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3927 - loss: 0.9943 - val_accuracy: 0.4134 - val_loss: 0.9602\n",
      "Epoch 51/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4137 - loss: 0.9481 - val_accuracy: 0.4134 - val_loss: 0.9570\n",
      "Epoch 52/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3909 - loss: 1.0050 - val_accuracy: 0.4134 - val_loss: 0.9539\n",
      "Epoch 53/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4064 - loss: 0.9900 - val_accuracy: 0.4134 - val_loss: 0.9509\n",
      "Epoch 54/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3901 - loss: 0.9714 - val_accuracy: 0.4134 - val_loss: 0.9478\n",
      "Epoch 55/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3794 - loss: 1.0014 - val_accuracy: 0.4134 - val_loss: 0.9447\n",
      "Epoch 56/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3665 - loss: 0.9939 - val_accuracy: 0.4134 - val_loss: 0.9416\n",
      "Epoch 57/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4177 - loss: 0.9282 - val_accuracy: 0.4134 - val_loss: 0.9387\n",
      "Epoch 58/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3840 - loss: 0.9638 - val_accuracy: 0.4134 - val_loss: 0.9356\n",
      "Epoch 59/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4186 - loss: 0.9228 - val_accuracy: 0.4134 - val_loss: 0.9326\n",
      "Epoch 60/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3765 - loss: 1.0018 - val_accuracy: 0.4190 - val_loss: 0.9296\n",
      "Epoch 61/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4188 - loss: 0.9367 - val_accuracy: 0.4190 - val_loss: 0.9266\n",
      "Epoch 62/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3944 - loss: 0.9546 - val_accuracy: 0.4190 - val_loss: 0.9237\n",
      "Epoch 63/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4258 - loss: 0.9191 - val_accuracy: 0.4190 - val_loss: 0.9208\n",
      "Epoch 64/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4286 - loss: 0.9208 - val_accuracy: 0.4190 - val_loss: 0.9177\n",
      "Epoch 65/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3851 - loss: 0.9487 - val_accuracy: 0.4190 - val_loss: 0.9147\n",
      "Epoch 66/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3853 - loss: 0.9345 - val_accuracy: 0.4190 - val_loss: 0.9118\n",
      "Epoch 67/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3949 - loss: 0.9414 - val_accuracy: 0.4190 - val_loss: 0.9089\n",
      "Epoch 68/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4258 - loss: 0.8945 - val_accuracy: 0.4190 - val_loss: 0.9060\n",
      "Epoch 69/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4378 - loss: 0.8959 - val_accuracy: 0.4190 - val_loss: 0.9032\n",
      "Epoch 70/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3838 - loss: 0.9334 - val_accuracy: 0.4190 - val_loss: 0.9002\n",
      "Epoch 71/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3877 - loss: 0.9400 - val_accuracy: 0.4190 - val_loss: 0.8973\n",
      "Epoch 72/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4258 - loss: 0.8633 - val_accuracy: 0.4246 - val_loss: 0.8945\n",
      "Epoch 73/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3929 - loss: 0.9232 - val_accuracy: 0.4246 - val_loss: 0.8917\n",
      "Epoch 74/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4037 - loss: 0.9265 - val_accuracy: 0.4246 - val_loss: 0.8888\n",
      "Epoch 75/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4218 - loss: 0.8638 - val_accuracy: 0.4246 - val_loss: 0.8861\n",
      "Epoch 76/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4017 - loss: 0.8979 - val_accuracy: 0.4246 - val_loss: 0.8833\n",
      "Epoch 77/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4055 - loss: 0.9165 - val_accuracy: 0.4302 - val_loss: 0.8805\n",
      "Epoch 78/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4312 - loss: 0.8991 - val_accuracy: 0.4246 - val_loss: 0.8777\n",
      "Epoch 79/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3851 - loss: 0.9118 - val_accuracy: 0.4246 - val_loss: 0.8750\n",
      "Epoch 80/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4165 - loss: 0.8684 - val_accuracy: 0.4246 - val_loss: 0.8723\n",
      "Epoch 81/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4322 - loss: 0.8624 - val_accuracy: 0.4246 - val_loss: 0.8696\n",
      "Epoch 82/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4271 - loss: 0.8653 - val_accuracy: 0.4246 - val_loss: 0.8668\n",
      "Epoch 83/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4252 - loss: 0.8781 - val_accuracy: 0.4246 - val_loss: 0.8642\n",
      "Epoch 84/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4281 - loss: 0.8794 - val_accuracy: 0.4246 - val_loss: 0.8614\n",
      "Epoch 85/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4103 - loss: 0.8942 - val_accuracy: 0.4246 - val_loss: 0.8588\n",
      "Epoch 86/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4171 - loss: 0.8740 - val_accuracy: 0.4246 - val_loss: 0.8561\n",
      "Epoch 87/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4152 - loss: 0.8685 - val_accuracy: 0.4246 - val_loss: 0.8535\n",
      "Epoch 88/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4550 - loss: 0.8367 - val_accuracy: 0.4246 - val_loss: 0.8508\n",
      "Epoch 89/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4261 - loss: 0.8671 - val_accuracy: 0.4302 - val_loss: 0.8482\n",
      "Epoch 90/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4331 - loss: 0.8289 - val_accuracy: 0.4302 - val_loss: 0.8456\n",
      "Epoch 91/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3907 - loss: 0.8800 - val_accuracy: 0.4302 - val_loss: 0.8430\n",
      "Epoch 92/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4424 - loss: 0.8312 - val_accuracy: 0.4302 - val_loss: 0.8405\n",
      "Epoch 93/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4445 - loss: 0.8344 - val_accuracy: 0.4302 - val_loss: 0.8379\n",
      "Epoch 94/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4266 - loss: 0.8553 - val_accuracy: 0.4302 - val_loss: 0.8353\n",
      "Epoch 95/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4413 - loss: 0.8506 - val_accuracy: 0.4246 - val_loss: 0.8328\n",
      "Epoch 96/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4312 - loss: 0.8514 - val_accuracy: 0.4246 - val_loss: 0.8303\n",
      "Epoch 97/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4219 - loss: 0.8526 - val_accuracy: 0.4246 - val_loss: 0.8277\n",
      "Epoch 98/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4448 - loss: 0.8335 - val_accuracy: 0.4246 - val_loss: 0.8252\n",
      "Epoch 99/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4264 - loss: 0.8540 - val_accuracy: 0.4246 - val_loss: 0.8227\n",
      "Epoch 100/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4228 - loss: 0.8495 - val_accuracy: 0.4246 - val_loss: 0.8203\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4049 - loss: 0.8291 \n",
      "Score: 0.42458099126815796 for parameters: {'learning_rate': 1e-05, 'num_layers': 1, 'neurons_per_layer': 32, 'batch_size': 16, 'dropout': 0.2}\n",
      "Evaluating combination: {'learning_rate': 1e-05, 'num_layers': 2, 'neurons_per_layer': 32, 'batch_size': 16, 'dropout': 0.2}\n",
      "Epoch 1/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6523 - loss: 0.6686 - val_accuracy: 0.6872 - val_loss: 0.6618\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.6858 - val_accuracy: 0.6872 - val_loss: 0.6590\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6844 - loss: 0.6725 - val_accuracy: 0.6927 - val_loss: 0.6563\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6856 - loss: 0.6272 - val_accuracy: 0.6983 - val_loss: 0.6537\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6702 - loss: 0.6847 - val_accuracy: 0.6927 - val_loss: 0.6510\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6678 - loss: 0.6676 - val_accuracy: 0.6983 - val_loss: 0.6485\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6600 - loss: 0.6587 - val_accuracy: 0.7039 - val_loss: 0.6461\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.6765 - val_accuracy: 0.7095 - val_loss: 0.6436\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6343 - loss: 0.6726 - val_accuracy: 0.7318 - val_loss: 0.6412\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6341 - loss: 0.6903 - val_accuracy: 0.7318 - val_loss: 0.6388\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 0.6463 - val_accuracy: 0.7318 - val_loss: 0.6364\n",
      "Epoch 12/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6676 - loss: 0.6650 - val_accuracy: 0.7263 - val_loss: 0.6342\n",
      "Epoch 13/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.6531 - val_accuracy: 0.7374 - val_loss: 0.6320\n",
      "Epoch 14/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.6447 - val_accuracy: 0.7430 - val_loss: 0.6298\n",
      "Epoch 15/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.6158 - val_accuracy: 0.7430 - val_loss: 0.6276\n",
      "Epoch 16/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6657 - loss: 0.6763 - val_accuracy: 0.7430 - val_loss: 0.6254\n",
      "Epoch 17/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.6447 - val_accuracy: 0.7430 - val_loss: 0.6235\n",
      "Epoch 18/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6851 - loss: 0.6422 - val_accuracy: 0.7486 - val_loss: 0.6215\n",
      "Epoch 19/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.6507 - val_accuracy: 0.7486 - val_loss: 0.6194\n",
      "Epoch 20/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6582 - loss: 0.6435 - val_accuracy: 0.7486 - val_loss: 0.6175\n",
      "Epoch 21/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 0.6375 - val_accuracy: 0.7430 - val_loss: 0.6155\n",
      "Epoch 22/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6893 - loss: 0.6346 - val_accuracy: 0.7430 - val_loss: 0.6136\n",
      "Epoch 23/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6952 - loss: 0.6319 - val_accuracy: 0.7430 - val_loss: 0.6117\n",
      "Epoch 24/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7041 - loss: 0.6158 - val_accuracy: 0.7430 - val_loss: 0.6098\n",
      "Epoch 25/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.6402 - val_accuracy: 0.7430 - val_loss: 0.6080\n",
      "Epoch 26/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6810 - loss: 0.6369 - val_accuracy: 0.7430 - val_loss: 0.6062\n",
      "Epoch 27/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.6236 - val_accuracy: 0.7430 - val_loss: 0.6043\n",
      "Epoch 28/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7006 - loss: 0.6132 - val_accuracy: 0.7430 - val_loss: 0.6024\n",
      "Epoch 29/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7199 - loss: 0.5933 - val_accuracy: 0.7430 - val_loss: 0.6008\n",
      "Epoch 30/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.6288 - val_accuracy: 0.7430 - val_loss: 0.5990\n",
      "Epoch 31/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 0.6004 - val_accuracy: 0.7430 - val_loss: 0.5973\n",
      "Epoch 32/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7186 - loss: 0.6173 - val_accuracy: 0.7486 - val_loss: 0.5956\n",
      "Epoch 33/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7033 - loss: 0.6218 - val_accuracy: 0.7486 - val_loss: 0.5939\n",
      "Epoch 34/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7145 - loss: 0.6150 - val_accuracy: 0.7486 - val_loss: 0.5923\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.5848 \n",
      "Score: 0.748603343963623 for parameters: {'learning_rate': 1e-05, 'num_layers': 2, 'neurons_per_layer': 32, 'batch_size': 16, 'dropout': 0.2}\n",
      "Best params: {'learning_rate': 1e-05, 'num_layers': 2, 'neurons_per_layer': 32, 'batch_size': 16, 'dropout': 0.2} with score: 0.748603343963623\n",
      "Execution time of run: 23.0593 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [1e-5, 1e-4, 1e-3],\n",
    "    'num_layers': [1, 2, 3],\n",
    "    'neurons_per_layer': [32, 64, 128],\n",
    "    'batch_size': [16, 32],\n",
    "    'dropout': [0.2, 0.3],\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-5],\n",
    "    'num_layers': [1, 2],\n",
    "    'neurons_per_layer': [32],\n",
    "    'batch_size': [16],\n",
    "    'dropout': [0.2],\n",
    "}\n",
    "\n",
    "grid_search_optimizer = GridSearchOptimizer(param_grid)\n",
    "best_hyperparameters = grid_search_optimizer.run(Model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
