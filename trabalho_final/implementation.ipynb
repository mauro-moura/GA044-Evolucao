{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vuJEjkJ4Wl4z"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dRoUDckjWl43"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def measure_execution_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Execution time of {func.__name__}: {execution_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "abpT9zcxWl45"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, hyperparameters):\n",
    "        self.hyperparameters = hyperparameters\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Data from: https://www.kaggle.com/code/stefanbergstein/keras-deep-learning-on-titanic-data\n",
    "        \"\"\"\n",
    "        data = pd.read_csv('dataset/train.csv')\n",
    "        # Fill missing values\n",
    "        # Fill numerical columns with the median value\n",
    "        data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "        data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "        data['Sex'] = data['Sex'].fillna(data['Sex'].mode()[0])\n",
    "        data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "\n",
    "        variables = ['Pclass','Sex', 'Age','Parch','SibSp','Embarked']\n",
    "        x = data[variables]\n",
    "        y = data[['Survived']]\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        x.loc[:, 'Sex'] = le.fit_transform(x['Sex'])\n",
    "        x.loc[:, 'Embarked'] = le.fit_transform(x['Embarked'])\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x = x.astype('float64')\n",
    "        x.loc[:, variables] = scaler.fit_transform(x[variables]).astype('float64')\n",
    "\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        return self.x_train, self.y_train\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = tf.keras.layers.Input(shape=(self.x_train.shape[1],))\n",
    "\n",
    "        dense = tf.keras.layers.Dense(self.hyperparameters['neurons_per_layer'], activation = 'relu', kernel_initializer = 'he_normal')(input_layer)\n",
    "        for _ in range(self.hyperparameters['num_layers'] - 1):\n",
    "            dense = tf.keras.layers.Dense(self.hyperparameters['neurons_per_layer'], activation = 'relu', kernel_initializer = 'he_normal')(dense)\n",
    "            if self.hyperparameters['dropout'] > 0:\n",
    "                dense = tf.keras.layers.Dropout(self.hyperparameters['dropout'])(dense)\n",
    "\n",
    "        output_layer = tf.keras.layers.Dense(1,activation = 'sigmoid')(dense)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.hyperparameters['learning_rate'])\n",
    "        model.compile(loss='binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5)]\n",
    "        self.score = self.model.fit(self.x_train, self.y_train, epochs=100, batch_size=self.hyperparameters['batch_size'],\n",
    "                               validation_data=(self.x_val, self.y_val), callbacks=callbacks)\n",
    "\n",
    "        return self.score\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate the model on the validation set.\"\"\"\n",
    "        return self.model.evaluate(self.x_val, self.y_val)[1]\n",
    "\n",
    "    def run(self):\n",
    "        self.load_data()\n",
    "        self.build_model()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOjrBY9jWl47",
    "outputId": "9a454b06-c8f9-4cff-99ac-0419ddada24f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4149 - loss: 0.9356 - val_accuracy: 0.5307 - val_loss: 0.8154\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5247 - loss: 0.8498 - val_accuracy: 0.5475 - val_loss: 0.7655\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5213 - loss: 0.8014 - val_accuracy: 0.6369 - val_loss: 0.7213\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5421 - loss: 0.8124 - val_accuracy: 0.6425 - val_loss: 0.6835\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5977 - loss: 0.7644 - val_accuracy: 0.6425 - val_loss: 0.6510\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6104 - loss: 0.7132 - val_accuracy: 0.6480 - val_loss: 0.6237\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6381 - loss: 0.6698 - val_accuracy: 0.6760 - val_loss: 0.6001\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.6263 - val_accuracy: 0.6927 - val_loss: 0.5803\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6606 - loss: 0.6630 - val_accuracy: 0.7263 - val_loss: 0.5631\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6537 - loss: 0.6556 - val_accuracy: 0.7821 - val_loss: 0.5473\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6539 - loss: 0.6254 - val_accuracy: 0.8045 - val_loss: 0.5340\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7006 - loss: 0.5798 - val_accuracy: 0.7989 - val_loss: 0.5224\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.5732 - val_accuracy: 0.8045 - val_loss: 0.5110\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.5389 - val_accuracy: 0.8045 - val_loss: 0.5007\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7620 - loss: 0.5230 - val_accuracy: 0.8101 - val_loss: 0.4927\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.5839 - val_accuracy: 0.8101 - val_loss: 0.4858\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.5285 - val_accuracy: 0.8101 - val_loss: 0.4798\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7423 - loss: 0.5330 - val_accuracy: 0.7933 - val_loss: 0.4742\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7709 - loss: 0.5018 - val_accuracy: 0.7933 - val_loss: 0.4677\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7796 - loss: 0.5006 - val_accuracy: 0.7933 - val_loss: 0.4635\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.5131 - val_accuracy: 0.7933 - val_loss: 0.4599\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.4678 - val_accuracy: 0.7933 - val_loss: 0.4555\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.5015 - val_accuracy: 0.7933 - val_loss: 0.4521\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.4984 - val_accuracy: 0.7933 - val_loss: 0.4487\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4560 - val_accuracy: 0.7989 - val_loss: 0.4454\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 0.5060 - val_accuracy: 0.8101 - val_loss: 0.4436\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.5075 - val_accuracy: 0.8101 - val_loss: 0.4418\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.4526 - val_accuracy: 0.8101 - val_loss: 0.4392\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.4550 - val_accuracy: 0.8101 - val_loss: 0.4370\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7940 - loss: 0.4821 - val_accuracy: 0.8101 - val_loss: 0.4361\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.5076 - val_accuracy: 0.8101 - val_loss: 0.4348\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.4727 - val_accuracy: 0.8101 - val_loss: 0.4340\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.4672 - val_accuracy: 0.8045 - val_loss: 0.4317\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'learning_rate': 10**-4,\n",
    "    'num_layers': 2,\n",
    "    'neurons_per_layer': 64,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.3,\n",
    "}\n",
    "model = Model(hyperparameters)\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbH_v54JWl49"
   },
   "source": [
    "# Optmize\n",
    "\n",
    "- Learning rate: 1e-6 an 1e-1\n",
    "- Number of hidden Layers\n",
    "- Batch Size\n",
    "- Number of neurons\n",
    "- Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XIOYiVupWl5A"
   },
   "outputs": [],
   "source": [
    "class Evolution():\n",
    "    def __init__(self, population_size, generations, mutation_rate, crossover_rate):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.population = []\n",
    "\n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize the population with random hyperparameter configurations.\"\"\"\n",
    "        for _ in range(self.population_size):\n",
    "            individual = {\n",
    "                'learning_rate': 10**random.uniform(-6, -1),\n",
    "                'num_layers': random.randint(1, 5),\n",
    "                'neurons_per_layer': random.choice([32, 64, 128, 256, 512]),\n",
    "                'batch_size': random.choice([16, 32, 64, 128]),\n",
    "                'dropout': random.uniform(0.1, 0.5),\n",
    "            }\n",
    "            self.population.append(individual)\n",
    "\n",
    "    def evaluate_population(self, model_class: Model):\n",
    "        \"\"\"Evaluate the fitness of the population based on validation accuracy.\"\"\"\n",
    "        fitness_scores = []\n",
    "        for individual in self.population:\n",
    "            model = model_class(individual)\n",
    "            model.load_data()\n",
    "            model.build_model()\n",
    "            model.train()\n",
    "            score = model.evaluate()\n",
    "            fitness_scores.append(score)\n",
    "        return fitness_scores\n",
    "\n",
    "    def select_parents(self, fitness_scores): # Discordo\n",
    "        \"\"\"Select parents using tournament selection.\"\"\"\n",
    "        selected_parents = []\n",
    "        for _ in range(self.population_size):\n",
    "            min_candidates = min(5, len(fitness_scores))\n",
    "            candidates = random.sample(list(zip(self.population, fitness_scores)), min_candidates)\n",
    "            best_candidate = max(candidates, key=lambda x: x[1])\n",
    "            selected_parents.append(best_candidate[0])\n",
    "        return selected_parents\n",
    "\n",
    "    def crossover(self, parent1:dict, parent2:dict):\n",
    "        \"\"\"Perform single-point crossover.\"\"\"\n",
    "        child1 = parent1.copy()\n",
    "        child2 = parent1.copy()\n",
    "        if random.random() < self.crossover_rate:\n",
    "            crossover_point = random.randint(1, len(parent1.keys())-1)\n",
    "            parent_keys = sorted(parent2.keys())\n",
    "            for key in parent_keys[crossover_point:]:\n",
    "                child1[key] = parent2[key]\n",
    "            for key in parent_keys[:crossover_point]:\n",
    "                child2[key] = parent2[key]\n",
    "        return child1, child2\n",
    "\n",
    "    def mutate(self, individual):\n",
    "        \"\"\"Perform mutation on the individual.\"\"\"\n",
    "        for mutation_point in list(individual.keys()):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mutation_value = self.get_mutation_value(mutation_point)\n",
    "                individual[mutation_point] = mutation_value\n",
    "        return individual\n",
    "\n",
    "    def get_mutation_value(self, parameter):\n",
    "        \"\"\"Generate a new value for a mutated parameter.\"\"\"\n",
    "        if parameter == 'learning_rate':\n",
    "            return 10**random.uniform(-6, -1)\n",
    "        elif parameter == 'num_layers':\n",
    "            return random.randint(1, 5)\n",
    "        elif parameter == 'neurons_per_layer':\n",
    "            return random.choice([32, 64, 128, 256, 512])\n",
    "        elif parameter == 'batch_size':\n",
    "            return random.choice([16, 32, 64, 128])\n",
    "        elif parameter == 'dropout':\n",
    "            return random.uniform(0, 0.5)\n",
    "\n",
    "    def genetic_drift(self):\n",
    "        \"\"\"Introduce genetic drift (randomly changing some individuals).\"\"\"\n",
    "        individual = random.choice(self.population)\n",
    "        self.mutate(individual)\n",
    "\n",
    "    @measure_execution_time\n",
    "    def run(self, model_class):\n",
    "        best_global = []\n",
    "        self.initialize_population()\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            print(f\"Generation {generation + 1}/{self.generations}\")\n",
    "            fitness_scores = self.evaluate_population(model_class)\n",
    "            parents = self.select_parents(fitness_scores)\n",
    "\n",
    "            # Crossover and mutation to create new population\n",
    "            new_population = []\n",
    "            for i in range(0, len(parents), 2):\n",
    "                parent1 = parents[i]\n",
    "                parent2 = parents[i + 1]\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                # new_population.append(self.mutate(child1))\n",
    "                # new_population.append(self.mutate(child2))\n",
    "                new_population.append(child1)\n",
    "                new_population.append(child2)\n",
    "\n",
    "            self.population = new_population\n",
    "            # Perform genetic drift\n",
    "            self.genetic_drift()\n",
    "\n",
    "            # Perform mutation\n",
    "            for i in range(len(self.population)):\n",
    "                self.population[i] = self.mutate(self.population[i])\n",
    "\n",
    "            print(self.population, fitness_scores)\n",
    "            best_individual = max(zip(self.population, fitness_scores), key=lambda x: x[1])\n",
    "            best_global.append(best_individual)\n",
    "            print(f\"Best fitness in generation {generation + 1}: {best_individual[1]}\")\n",
    "\n",
    "        return best_individual, best_global  # Return the best individual after all generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z_seGq1Wl5C",
    "outputId": "a6daae40-66fd-4264-9d01-55542fc75809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/2\n",
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4960 - loss: 0.9740 - val_accuracy: 0.6536 - val_loss: 0.6551\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5740 - loss: 0.8821 - val_accuracy: 0.6760 - val_loss: 0.6168\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5932 - loss: 0.8070 - val_accuracy: 0.7095 - val_loss: 0.5856\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6002 - loss: 0.7857 - val_accuracy: 0.7318 - val_loss: 0.5568\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6285 - loss: 0.7683 - val_accuracy: 0.7542 - val_loss: 0.5324\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6240 - loss: 0.7359 - val_accuracy: 0.7709 - val_loss: 0.5118\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6313 - loss: 0.7080 - val_accuracy: 0.7821 - val_loss: 0.4940\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6803 - loss: 0.6899 - val_accuracy: 0.7989 - val_loss: 0.4797\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6738 - loss: 0.6628 - val_accuracy: 0.7877 - val_loss: 0.4674\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6559 - loss: 0.6940 - val_accuracy: 0.7877 - val_loss: 0.4569\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6832 - loss: 0.6376 - val_accuracy: 0.7933 - val_loss: 0.4490\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6737 - loss: 0.7189 - val_accuracy: 0.7877 - val_loss: 0.4428\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6966 - loss: 0.6182 - val_accuracy: 0.7821 - val_loss: 0.4372\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6862 - loss: 0.6655 - val_accuracy: 0.7877 - val_loss: 0.4320\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7197 - loss: 0.6367 - val_accuracy: 0.7877 - val_loss: 0.4273\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7404 - loss: 0.5890 - val_accuracy: 0.7821 - val_loss: 0.4239\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7174 - loss: 0.6466 - val_accuracy: 0.7821 - val_loss: 0.4206\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7489 - loss: 0.6084 - val_accuracy: 0.7989 - val_loss: 0.4178\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7576 - loss: 0.6006 - val_accuracy: 0.8045 - val_loss: 0.4150\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7442 - loss: 0.5390 - val_accuracy: 0.8045 - val_loss: 0.4126\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7340 - loss: 0.6155 - val_accuracy: 0.8101 - val_loss: 0.4105\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7641 - loss: 0.5323 - val_accuracy: 0.8045 - val_loss: 0.4086\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7165 - loss: 0.6319 - val_accuracy: 0.8045 - val_loss: 0.4072\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7694 - loss: 0.5509 - val_accuracy: 0.8101 - val_loss: 0.4059\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7620 - loss: 0.5462 - val_accuracy: 0.8156 - val_loss: 0.4047\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.3879 \n",
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4692 - loss: 1.0244 - val_accuracy: 0.5978 - val_loss: 0.6996\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6240 - loss: 0.7369 - val_accuracy: 0.6927 - val_loss: 0.6247\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6707 - loss: 0.6571 - val_accuracy: 0.7486 - val_loss: 0.5137\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7520 - loss: 0.5772 - val_accuracy: 0.7542 - val_loss: 0.4803\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7270 - loss: 0.5868 - val_accuracy: 0.7933 - val_loss: 0.4606\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7357 - loss: 0.5763 - val_accuracy: 0.8045 - val_loss: 0.4591\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7847 - loss: 0.5236 - val_accuracy: 0.8156 - val_loss: 0.4454\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7893 - loss: 0.4863 - val_accuracy: 0.8212 - val_loss: 0.4454\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7968 - loss: 0.4963 - val_accuracy: 0.8156 - val_loss: 0.4444\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7639 - loss: 0.5281 - val_accuracy: 0.8156 - val_loss: 0.4452\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7824 - loss: 0.4992 - val_accuracy: 0.8156 - val_loss: 0.4470\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7836 - loss: 0.4930 - val_accuracy: 0.8156 - val_loss: 0.4402\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7980 - loss: 0.4691 - val_accuracy: 0.8212 - val_loss: 0.4493\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7824 - loss: 0.5128 - val_accuracy: 0.8268 - val_loss: 0.4445\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7785 - loss: 0.5153 - val_accuracy: 0.8212 - val_loss: 0.4466\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8022 - loss: 0.4362 - val_accuracy: 0.8268 - val_loss: 0.4473\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7952 - loss: 0.4626 - val_accuracy: 0.8268 - val_loss: 0.4482\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7895 - loss: 0.4861 - val_accuracy: 0.8268 - val_loss: 0.4506\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8188 - loss: 0.4582 - val_accuracy: 0.8101 - val_loss: 0.4467\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8183 - loss: 0.4403 - val_accuracy: 0.8101 - val_loss: 0.4457\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8146 - loss: 0.4437 - val_accuracy: 0.8156 - val_loss: 0.4439\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7930 - loss: 0.5030 - val_accuracy: 0.8212 - val_loss: 0.4433\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7739 - loss: 0.5074 - val_accuracy: 0.8212 - val_loss: 0.4466\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8107 - loss: 0.4509 - val_accuracy: 0.8156 - val_loss: 0.4482\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8223 - loss: 0.4556 - val_accuracy: 0.8212 - val_loss: 0.4537\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8172 - loss: 0.4525 - val_accuracy: 0.8156 - val_loss: 0.4558\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4219 \n",
      "[{'learning_rate': 2.1607786978654324e-05, 'num_layers': 4, 'neurons_per_layer': 512, 'batch_size': 64, 'dropout': 0.16601047794450097}, {'learning_rate': 0.006472541369965114, 'num_layers': 4, 'neurons_per_layer': 512, 'batch_size': 32, 'dropout': 0.061744310593343676}] [0.8156424760818481, 0.8156424760818481]\n",
      "Best fitness in generation 1: 0.8156424760818481\n",
      "Generation 2/2\n",
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5962 - loss: 0.8278 - val_accuracy: 0.7318 - val_loss: 0.5810\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7031 - loss: 0.6262 - val_accuracy: 0.7821 - val_loss: 0.4984\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6999 - loss: 0.6039 - val_accuracy: 0.7877 - val_loss: 0.4653\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7569 - loss: 0.5316 - val_accuracy: 0.8156 - val_loss: 0.4512\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7666 - loss: 0.5238 - val_accuracy: 0.8156 - val_loss: 0.4442\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7397 - loss: 0.5661 - val_accuracy: 0.8156 - val_loss: 0.4409\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7676 - loss: 0.5360 - val_accuracy: 0.8101 - val_loss: 0.4445\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7681 - loss: 0.5321 - val_accuracy: 0.8156 - val_loss: 0.4367\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7767 - loss: 0.5433 - val_accuracy: 0.8101 - val_loss: 0.4362\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7779 - loss: 0.4716 - val_accuracy: 0.8045 - val_loss: 0.4389\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8011 - loss: 0.4832 - val_accuracy: 0.8045 - val_loss: 0.4400\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7992 - loss: 0.5050 - val_accuracy: 0.8045 - val_loss: 0.4376\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7874 - loss: 0.4813 - val_accuracy: 0.8156 - val_loss: 0.4473\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8352 - loss: 0.4342 - val_accuracy: 0.8045 - val_loss: 0.4450\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7819 - loss: 0.4895 - val_accuracy: 0.8101 - val_loss: 0.4363\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8019 - loss: 0.4830 - val_accuracy: 0.8101 - val_loss: 0.4424\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7771 - loss: 0.5077 - val_accuracy: 0.8101 - val_loss: 0.4428\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8233 - loss: 0.4474 - val_accuracy: 0.8156 - val_loss: 0.4551\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8101 - loss: 0.4735 - val_accuracy: 0.8156 - val_loss: 0.4517\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8078 - loss: 0.4680 - val_accuracy: 0.8156 - val_loss: 0.4483\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8069 - loss: 0.4325 - val_accuracy: 0.8156 - val_loss: 0.4481\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8128 - loss: 0.4305 - val_accuracy: 0.8156 - val_loss: 0.4472\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8092 - loss: 0.4549 - val_accuracy: 0.8156 - val_loss: 0.4501\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8239 - loss: 0.4457 - val_accuracy: 0.8156 - val_loss: 0.4467\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8076 - loss: 0.4480 - val_accuracy: 0.8101 - val_loss: 0.4483\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8005 - loss: 0.4609 - val_accuracy: 0.8156 - val_loss: 0.4486\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4192 \n",
      "Epoch 1/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6713 - loss: 3.3532 - val_accuracy: 0.8045 - val_loss: 0.4231\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8188 - loss: 0.4604 - val_accuracy: 0.7989 - val_loss: 0.4347\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 0.3974 - val_accuracy: 0.8045 - val_loss: 0.4497\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8537 - loss: 0.4018 - val_accuracy: 0.8156 - val_loss: 0.4495\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8202 - loss: 0.4496 - val_accuracy: 0.7765 - val_loss: 0.5964\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7905 - loss: 0.4534 - val_accuracy: 0.8212 - val_loss: 0.4296\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8276 - loss: 0.4137 - val_accuracy: 0.8212 - val_loss: 0.4630\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8019 - loss: 0.4274 - val_accuracy: 0.7989 - val_loss: 0.4560\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8245 - loss: 0.4262 - val_accuracy: 0.8268 - val_loss: 0.4601\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.4418 \n",
      "[{'learning_rate': 0.0015174348699686124, 'num_layers': 4, 'neurons_per_layer': 64, 'batch_size': 32, 'dropout': 0.061744310593343676}, {'learning_rate': 0.006472541369965114, 'num_layers': 4, 'neurons_per_layer': 512, 'batch_size': 32, 'dropout': 0.061744310593343676}] [0.8156424760818481, 0.826815664768219]\n",
      "Best fitness in generation 2: 0.826815664768219\n",
      "Execution time of run: 15.4291 seconds\n",
      "Best hyperparameters found: {'learning_rate': 0.006472541369965114, 'num_layers': 4, 'neurons_per_layer': 512, 'batch_size': 32, 'dropout': 0.061744310593343676} Best fitness found: 0.826815664768219\n"
     ]
    }
   ],
   "source": [
    "population_size = 10\n",
    "generations = 10\n",
    "mutation_rate = 0.25\n",
    "crossover_rate = 0.75\n",
    "\n",
    "evo_optimizer = Evolution(population_size, generations, mutation_rate, crossover_rate)\n",
    "best_individual, best_global = evo_optimizer.run(Model)\n",
    "best_hyperparameters, best_fitness = best_individual\n",
    "print(\"Best hyperparameters found:\", best_hyperparameters, \"Best fitness found:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_global_fitness = [best[1] for best in best_global]\n",
    "plt.plot(best_global_fitness)\n",
    "plt.plot(best_global_fitness, '*')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Best Fitness')\n",
    "plt.title('Evolution of the best fitness over generations')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xht295wIWl5D"
   },
   "source": [
    "# Grid Search Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ACoWqNW6Wl5E"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class GridSearchOptimizer:\n",
    "    def __init__(self, param_grid):\n",
    "        self.param_grid = param_grid\n",
    "        self.best_params = None\n",
    "        self.best_score = -np.inf  # Best score initialized to negative infinity\n",
    "\n",
    "    def generate_grid(self):\n",
    "        \"\"\"Generate all combinations of hyperparameters from the grid.\"\"\"\n",
    "        return list(itertools.product(*self.param_grid.values()))\n",
    "\n",
    "    def evaluate_combination(self, model_class, params):\n",
    "        \"\"\"Evaluate a single combination of hyperparameters.\"\"\"\n",
    "        model = model_class(params)\n",
    "        model.load_data()\n",
    "        model.build_model()\n",
    "        model.train()\n",
    "        score = model.evaluate()\n",
    "        return score\n",
    "\n",
    "    @measure_execution_time\n",
    "    def run(self, model_class):\n",
    "        \"\"\"Run the grid search over the parameter grid.\"\"\"\n",
    "        param_combinations = self.generate_grid()\n",
    "        params_len = len(param_combinations)\n",
    "        for i, params in enumerate(param_combinations):\n",
    "            params = {key: val for key, val in zip(self.param_grid.keys(), params)}\n",
    "            print(f\"Evaluating combination {i}/{params_len}: {params}\")\n",
    "            score = self.evaluate_combination(model_class, params)\n",
    "\n",
    "            # Track best score and parameters\n",
    "            if score > self.best_score:\n",
    "                self.best_score = score\n",
    "                self.best_params = params\n",
    "            print(f\"Score: {score} for parameters: {params}\")\n",
    "\n",
    "        print(f\"Best params: {self.best_params} with score: {self.best_score}\")\n",
    "        return self.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xHwf1BXYWl5F",
    "outputId": "8f35039f-716b-436c-f4cc-8317f46d3646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating combination 0/3000: {'learning_rate': 1e-06, 'num_layers': 1, 'neurons_per_layer': 32, 'batch_size': 16, 'dropout': np.float64(0.0)}\n",
      "Epoch 1/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5079 - loss: 0.8572 - val_accuracy: 0.5531 - val_loss: 0.9096\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5198 - loss: 0.8591 - val_accuracy: 0.5531 - val_loss: 0.9093\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5186 - loss: 0.8581 - val_accuracy: 0.5531 - val_loss: 0.9090\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5040 - loss: 0.8581 - val_accuracy: 0.5531 - val_loss: 0.9088\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4961 - loss: 0.8501 - val_accuracy: 0.5531 - val_loss: 0.9085\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4801 - loss: 0.8874 - val_accuracy: 0.5587 - val_loss: 0.9082\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4898 - loss: 0.8511 - val_accuracy: 0.5587 - val_loss: 0.9079\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5033 - loss: 0.8671 - val_accuracy: 0.5587 - val_loss: 0.9076\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 0.8521 - val_accuracy: 0.5587 - val_loss: 0.9073\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4893 - loss: 0.8747 - val_accuracy: 0.5587 - val_loss: 0.9071\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.8437 - val_accuracy: 0.5587 - val_loss: 0.9068\n",
      "Epoch 12/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4710 - loss: 0.8987 - val_accuracy: 0.5587 - val_loss: 0.9065\n",
      "Epoch 13/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5040 - loss: 0.8615 - val_accuracy: 0.5587 - val_loss: 0.9062\n",
      "Epoch 14/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4957 - loss: 0.8830 - val_accuracy: 0.5587 - val_loss: 0.9059\n",
      "Epoch 15/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5068 - loss: 0.8792 - val_accuracy: 0.5587 - val_loss: 0.9056\n",
      "Epoch 16/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5018 - loss: 0.8609 - val_accuracy: 0.5587 - val_loss: 0.9054\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m1e-1\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)),\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m grid_search_optimizer \u001b[38;5;241m=\u001b[39m GridSearchOptimizer(param_grid)\n\u001b[0;32m---> 10\u001b[0m best_hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mmeasure_execution_time.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      7\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m     execution_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m, in \u001b[0;36mGridSearchOptimizer.run\u001b[0;34m(self, model_class)\u001b[0m\n\u001b[1;32m     28\u001b[0m params \u001b[38;5;241m=\u001b[39m {key: val \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid\u001b[38;5;241m.\u001b[39mkeys(), params)}\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating combination \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_combination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Track best score and parameters\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score:\n",
      "Cell \u001b[0;32mIn[22], line 18\u001b[0m, in \u001b[0;36mGridSearchOptimizer.evaluate_combination\u001b[0;34m(self, model_class, params)\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mbuild_model()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)]\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:366\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    364\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    368\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:729\u001b[0m, in \u001b[0;36mTFEpochIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_epoch_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:102\u001b[0m, in \u001b[0;36mEpochIterator._enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps_per_epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, steps_per_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 709\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 748\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'num_layers': list(range(1, 5 + 1)),\n",
    "    'neurons_per_layer': [32, 64, 128, 256, 512],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'dropout': list(np.arange(0, 0.5, 0.1)),\n",
    "}\n",
    "\n",
    "grid_search_optimizer = GridSearchOptimizer(param_grid)\n",
    "best_hyperparameters = grid_search_optimizer.run(Model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
